#version 450 core

#include "common.h"
#include "header.h"
#include "matmul_conf.h"

#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
#extension GL_EXT_control_flow_attributes : enable

layout (constant_id = 0) const int act = 0;
layout (constant_id = 1) const int transpose_b = 0; // must be 1
layout (constant_id = 2) const float scale = 1.0;
layout (constant_id = 3) const float offset = 0;

struct Q8_0_Block
{
  float16_t d;
  uint8_t items[Q8_0_ITEMS_PER_BLOCK];
};

layout (binding = 0) readonly buffer InputTensor0
{
  float16_t input_tensor0[];
};

layout (binding = 1) readonly buffer InputTensor1
{
  Q8_0_Block input_tensor1[];
};
layout (binding = 2) writeonly buffer OutputTensor0
{
  float16_t output_tensor0[];
};

// [M, K] x [K, N] = [M, N]
// C = channels, M = a.height, N = b.height, K = a.width
layout (push_constant) uniform constants
{
  ShapeConstant shape0;
  ShapeConstant shape1;
  ShapeConstant shape2;
};

void
main ()
{
  uint gid_x = gl_WorkGroupID.x * Q8_0_TILE_X_SIZE;
  uint gid_y = gl_GlobalInvocationID.y;
  uint gid_z = gl_GlobalInvocationID.z;

  uint C = shape0.c;
  uint M = shape0.h;
  uint N = shape1.h;
  uint K = shape0.w;

  uint cs0 = shape0.cs / 2;
  uint hs0 = shape0.hs / 2;
  uint cs1 = shape1.cs / 2;
  uint hs1 = shape1.hs / 2;
  uint cs2 = shape2.cs / 2;
  uint hs2 = shape2.hs / 2;

  if (gid_x >= N || gid_y >= M || gid_z >= C)
    {
      return;
    }

  float sums[Q8_0_TILE_X_SIZE];

  [[unroll]] for (uint i = 0; i < Q8_0_TILE_X_SIZE; ++i)
    {
      sums[i] = 0;
    }

  uint block_counts = (K + Q8_0_ITEMS_PER_BLOCK - 1) / Q8_0_ITEMS_PER_BLOCK;

  uint offset_a = gid_z * cs0 + gid_y * hs0;

  // subgroup shape = [8, 4]
  uint ix = gl_SubgroupInvocationID.x / 4; // ix: block
  uint il = gl_SubgroupInvocationID.x % 4; // il: items in block

  uint ba = offset_a + ix * Q8_0_ITEMS_PER_BLOCK + il * 8;
  // parallel for 8 blocks
  [[unroll]] for (uint bi = ix; bi < block_counts; bi += gl_SubgroupSize / 4)
    {

      float tmp[Q8_0_TILE_K_SIZE];
      for (uint i = 0; i < Q8_0_TILE_K_SIZE; ++i)
        {
          tmp[i] = float (input_tensor0[ba + i]);
        }

      uint offset_b = gid_z * cs1 + gid_x * block_counts + bi;
      uint block_offset = offset_b;
      for (uint r = 0; r < Q8_0_TILE_X_SIZE; ++r)
        {
          // uint block_offset
          //     = (gid_z * shape1.cs / 2 + (gid_x + r) * block_counts);

          float d = float (input_tensor1[block_offset].d);
          float sum_b = .0;

          uint d_offset = il * 8;
          for (uint i = 0; i < Q8_0_TILE_K_SIZE; ++i)
            {
              uint di = d_offset + i;

              float a = tmp[i];
              float b = float (int8_t (input_tensor1[block_offset].items[di]));
              sum_b += (a * b);
            }
          sums[r] += sum_b * d;
          block_offset += block_counts;
        }

      // next 8 blocks
      ba += 8 * Q8_0_ITEMS_PER_BLOCK;
    }

  uint output_offset = gid_z * cs2 + gid_y * hs2 + gid_x;
  [[unroll]] for (uint r = 0; r < Q8_0_TILE_X_SIZE; ++r)
    {
      if (gid_x + r >= N)
        break;

      float v = subgroupAdd (sums[r]) * scale + offset;
      v = act == 1 ? v / (1.0 + exp (-v)) : v;

      if (subgroupElect ())
        {
          output_tensor0[output_offset + r] = float16_t (v);
        }
    }
}
