#version 450 core

#include "common.h"

#extension GL_KHR_shader_subgroup_arithmetic : require
#extension GL_EXT_shader_16bit_storage : require
#extension GL_EXT_shader_8bit_storage : require
#extension GL_EXT_shader_explicit_arithmetic_types_int8 : require
#extension GL_EXT_shader_explicit_arithmetic_types_int16 : require
#extension GL_EXT_shader_explicit_arithmetic_types_float16 : require
#extension GL_EXT_control_flow_attributes : enable

layout (constant_id = 0) const int act = 0;
layout (constant_id = 1) const int transpose_b = 0; // must be 1
layout (constant_id = 2) const float scale = 1.0;
layout (constant_id = 3) const float offset = 0;

layout (binding = 0) readonly buffer InputTensor0
{
  float16_t input_tensor0[];
};

layout (binding = 1) readonly buffer InputTensor1 { uint8_t input_tensor1[]; };
layout (binding = 2) writeonly buffer OutputTensor0
{
  float16_t output_tensor0[];
};

layout (push_constant) uniform constants
{
  int C;
  int M;
  int N;
  int K;
};

#define TILE_X_SIZE 1
#define TILE_K_SIZE 16

void
main ()
{
  uint gid_x = gl_WorkGroupID.x * TILE_X_SIZE;
  uint gid_y = gl_GlobalInvocationID.y;
  uint gid_z = gl_GlobalInvocationID.z;

  if (gid_x >= N || gid_y >= M || gid_z >= C)
    {
      return;
    }

  float sums[TILE_X_SIZE];

  [[unroll]] for (uint i = 0; i < TILE_X_SIZE; ++i)
    {
      sums[i] = 0;
    }

  uint group_counts = (K + Q8_0_ITEMS_PER_BLOCK - 1) / Q8_0_ITEMS_PER_BLOCK;
  uint QK = group_counts * Q8_0_BYTES_PER_BLOCK;

  uint offset_a = gid_z * M * K + gid_y * K;

  // tile size of K = 8
  // tile size of row = 8
  [[unroll]] for (uint ti = gl_SubgroupInvocationID.x * TILE_K_SIZE; ti < K;
                  ti += TILE_K_SIZE * gl_SubgroupSize)
    {

      uint block_id = ti / Q8_0_ITEMS_PER_BLOCK;

      float tmp[TILE_K_SIZE];

      for (uint i = 0; i < TILE_K_SIZE; ++i)
        {
          uint ai = offset_a + ti + i;
          tmp[i] = float (input_tensor0[ai]);
        }

      [[unroll]] for (uint r = 0; r < TILE_X_SIZE; ++r)
        {
          if (gid_x + r >= N)
            break;

          uint offset_b = gid_z * N * QK + (gid_x + r) * QK;
          uint block_offset = offset_b + block_id * Q8_0_BYTES_PER_BLOCK;

          uint u32scale = u8BufToU32 (input_tensor1, block_offset);
          float d = (uintBitsToFloat (u32scale));

          float sum_b = .0;
          for (uint i = 0; i < TILE_K_SIZE; ++i)
            {
              uint bi = block_offset + Q8_0_SCALE_BYTES
                        + (ti + i) % Q8_0_ITEMS_PER_BLOCK;

              if (ti + i >= K)
                break;

              float a = tmp[i];
              float b = float (int8_t (input_tensor1[bi]));
              sum_b += (a * b);
            }
          sums[r] += sum_b * d;
        }
    }

  [[unroll]] for (uint r = 0; r < TILE_X_SIZE; ++r)
    {
      if (gid_x + r >= N)
        break;
      float v = subgroupAdd (sums[r]) * scale + offset;
      v = act == 1 ? v / (1.0 + exp (-v)) : v;

      if (subgroupElect ())
        {
          output_tensor0[gid_z * M * N + gid_y * N + gid_x + r]
              = float16_t (v);
        }
    }
}
